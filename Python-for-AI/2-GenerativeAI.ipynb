{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Generative AI with Python\n",
    "\n",
    "Generative AI refers to a subset of artificial intelligence technologies and models that can generate new data similar to the data they were trained on. This can include anything from images, text, and music to more complex data types like videos. Generative AI has vast applications, including content creation, data augmentation, and even drug discovery.\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:875/1*NTJ-K2Rc2KdzjfWWCn1-7w.jpeg)\n",
    "\n",
    "**Generative AI — My Visualization**\n",
    "\n",
    "## The Mechanism Behind Generative AI\n",
    "\n",
    "At the core of generative AI are algorithms that are capable of learning patterns, features, and characteristics from vast amounts of data and then using this knowledge to generate new, unseen instances. These models don’t just replicate the input data but understand underlying structures to create relevant outputs. Following are the high level steps involved.\n",
    "\n",
    "-   **_Data Collection_**: Gather vast amounts of data from relevant sources.\n",
    "-   **_Data Preprocessing_**: Clean and prepare the data for analysis. This includes normalization, handling missing values, and feature extraction.\n",
    "-   **_Learning Patterns, Features, and Characteristics_**  \n",
    "    — Pattern Recognition: Analyze the data to identify patterns.  \n",
    "    — Feature Extraction: Identify significant features and characteristics within the data.\n",
    "-   **_Understanding Underlying Structures:_** Move beyond mere pattern recognition to understand the deeper structures and relationships within the data.\n",
    "-   **_Knowledge Synthesis:_** Integrate the learned patterns, features, and underlying structures to form a comprehensive understanding of the data.\n",
    "-   **_Generating New Instances:_** Use the synthesized knowledge to generate new, unseen instances that reflect the learned data structure but are not direct replications.\n",
    "\n",
    "## Key Technologies in Generative AI\n",
    "\n",
    "**_Neural Networks:_**\n",
    "\n",
    "The foundation of most generative AI models, especially deep learning networks, which can capture and model complex patterns in data.\n",
    "\n",
    "**_Generative Adversarial Networks (GANs):_**\n",
    "\n",
    "A revolutionary framework where two neural networks, the generator and the discriminator, are trained simultaneously in a competitive manner to produce high-quality, realistic outputs.\n",
    "\n",
    "**_Variational Autoencoders (VAEs):_**\n",
    "\n",
    "These are used for generating new data points by learning a distribution of the input data.\n",
    "\n",
    "**_Transformers:_**\n",
    "\n",
    "Originally designed for natural language processing tasks, transformers are now also being used for generating images, music, and more, thanks to their ability to handle sequential data effectively.\n",
    "\n",
    "## Python in Generative AI\n",
    "\n",
    "> Python is the lingua franca of AI development, owing to its simplicity and the powerful libraries available for machine learning and AI.\n",
    "\n",
    "## Key Python Libraries for Generative AI\n",
    "\n",
    "**_TensorFlow:_**\n",
    "\n",
    "TensorFlow provides a comprehensive, flexible ecosystem of tools, libraries, and community resources that lets researchers push the state-of-the-art in ML, and developers easily build and deploy ML-powered applications. Keras, a high-level API on top of TensorFlow, makes experimentation faster and more intuitive.\n",
    "\n",
    "**_PyTorch:_**\n",
    "\n",
    "Known for its simplicity, flexibility, and dynamic computation graph, PyTorch is favored for research and prototypes in generative AI.\n",
    "\n",
    "**_NumPy:_**\n",
    "\n",
    "Essential for handling numerical tasks in Python, NumPy is often used for its efficient array manipulation capabilities, serving as the backbone for more complex operations in AI models.\n",
    "\n",
    "## Getting Started with a Simple Python Example\n",
    "\n",
    "The code showcases how to use the `**_transformers_**` library by Hugging Face to answer questions programmatically using pre-trained AI models.\n",
    "\n",
    "**Setting Up**\n",
    "\n",
    "To begin, you’ll need the `**_transformers_**` library, which can be installed via pip, Python's package installer.\n",
    "\n",
    "```bash\n",
    "pip install transformers\n",
    "```\n",
    "\n",
    "**Load the Question-Answering Pipeline**\n",
    "\n",
    "First, we initialize the question-answering pipeline. This pipeline selects an appropriate pre-trained model optimized for answering questions.\n",
    "\n",
    "```bash \n",
    "from transformers import pipeline  \n",
    "question\\_answerer = pipeline(\"question-answering\")\n",
    "```\n",
    "\n",
    "**Define the Question and Context**\n",
    "\n",
    "The model needs two pieces of information: the question it needs to answer and the context containing the answer. In our example, the question is “What is the capital of France?”, and the context provided is a simple sentence stating that Paris is the capital of France.\n",
    "```bash\n",
    "question = \"What is the capital of France?\"context = \"France is a country in Western Europe. Its capital is Paris.\"\n",
    "```\n",
    "**Ask the Question**\n",
    "\n",
    "With the pipeline ready and our question and context defined, we ask the model to find the answer. The **_pipeline_** function processes the input and returns the most likely answer based on the context.\n",
    "```bash\n",
    "answer = question\\_answerer(question=question, context=context)  \n",
    "print(answer\\['answer'\\])\n",
    "```\n",
    "The model’s response, in this case, would be “Paris”, demonstrating its ability to extract information from the provided context accurately. I have executed the code in google colab environment and the detailed output is given below.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
